{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7853330,"sourceType":"datasetVersion","datasetId":4605904}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch\n!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T04:51:07.768371Z","iopub.execute_input":"2024-03-16T04:51:07.768755Z","iopub.status.idle":"2024-03-16T04:51:35.654606Z","shell.execute_reply.started":"2024-03-16T04:51:07.768728Z","shell.execute_reply":"2024-03-16T04:51:35.653342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n \n#data visualisation libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pylab import rcParams\n \nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n \n#to avoid warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:35.657068Z","iopub.execute_input":"2024-03-16T04:51:35.657395Z","iopub.status.idle":"2024-03-16T04:51:48.259656Z","shell.execute_reply.started":"2024-03-16T04:51:35.657363Z","shell.execute_reply":"2024-03-16T04:51:48.258864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/traintest/train.csv\")\nprint(data.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:48.260842Z","iopub.execute_input":"2024-03-16T04:51:48.261424Z","iopub.status.idle":"2024-03-16T04:51:50.159578Z","shell.execute_reply.started":"2024-03-16T04:51:48.261391Z","shell.execute_reply":"2024-03-16T04:51:50.158635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the class distribution of the 'label' column\ncolumn_labels = data.columns.tolist()[2:]\nlabel_counts = data[column_labels].sum().sort_values()\n\n\n# Create a black background for the plot\nplt.figure(figsize=(7, 5))\n\n# Create a horizontal bar plot using Seaborn\nax = sns.barplot(x=label_counts.values,\n\t\t\t\ty=label_counts.index, palette='viridis')\n\n\n# Add labels and title to the plot\nplt.xlabel('Number of Occurrences')\nplt.ylabel('Labels')\nplt.title('Distribution of Label Occurrences')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.160748Z","iopub.execute_input":"2024-03-16T04:51:50.161134Z","iopub.status.idle":"2024-03-16T04:51:50.513795Z","shell.execute_reply.started":"2024-03-16T04:51:50.161099Z","shell.execute_reply":"2024-03-16T04:51:50.512790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[column_labels].sum().sort_values()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.516579Z","iopub.execute_input":"2024-03-16T04:51:50.516900Z","iopub.status.idle":"2024-03-16T04:51:50.527830Z","shell.execute_reply.started":"2024-03-16T04:51:50.516872Z","shell.execute_reply":"2024-03-16T04:51:50.526875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create subsets based on toxic and clean comments\ntrain_toxic = data[data[column_labels].sum(axis=1) > 0]\ntrain_clean = data[data[column_labels].sum(axis=1) == 0]\n\n# Number of toxic and clean comments\nnum_toxic = len(train_toxic)\nnum_clean = len(train_clean)\n\n# Create a DataFrame for visualization\nplot_data = pd.DataFrame(\n\t{'Category': ['Toxic', 'Clean'], 'Count': [num_toxic, num_clean]})\n\n# Create a black background for the plot\nplt.figure(figsize=(7, 5))\n\n# Horizontal bar plot\nax = sns.barplot(x='Count', y='Category', data=plot_data, palette='viridis')\n\n\n# Add labels and title to the plot\nplt.xlabel('Number of Comments')\nplt.ylabel('Category')\nplt.title('Distribution of Toxic and Clean Comments')\n\n# Set ticks' color to white\nax.tick_params()\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.529153Z","iopub.execute_input":"2024-03-16T04:51:50.529434Z","iopub.status.idle":"2024-03-16T04:51:50.775885Z","shell.execute_reply.started":"2024-03-16T04:51:50.529410Z","shell.execute_reply":"2024-03-16T04:51:50.774966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_toxic.shape)\nprint(train_clean.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.777315Z","iopub.execute_input":"2024-03-16T04:51:50.778487Z","iopub.status.idle":"2024-03-16T04:51:50.783502Z","shell.execute_reply.started":"2024-03-16T04:51:50.778452Z","shell.execute_reply":"2024-03-16T04:51:50.782478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Randomly sample 15,000 clean comments\ntrain_clean_sampled = train_clean.sample(n=16225, random_state=42)\n\n# Combine the toxic and sampled clean comments\ndataframe = pd.concat([train_toxic, train_clean_sampled], axis=0)\n\n# Shuffle the data to avoid any order bias during training\ndataframe = data.sample(frac=1, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.785023Z","iopub.execute_input":"2024-03-16T04:51:50.786197Z","iopub.status.idle":"2024-03-16T04:51:50.837505Z","shell.execute_reply.started":"2024-03-16T04:51:50.786164Z","shell.execute_reply":"2024-03-16T04:51:50.836759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_toxic.shape)\nprint(train_clean_sampled.shape)\nprint(dataframe.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.838550Z","iopub.execute_input":"2024-03-16T04:51:50.838797Z","iopub.status.idle":"2024-03-16T04:51:50.843563Z","shell.execute_reply.started":"2024-03-16T04:51:50.838776Z","shell.execute_reply":"2024-03-16T04:51:50.842556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into training, testing sets & validation sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n\tdataframe['comment_text'], dataframe.iloc[:, 2:], test_size=0.25, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.845082Z","iopub.execute_input":"2024-03-16T04:51:50.845480Z","iopub.status.idle":"2024-03-16T04:51:50.883430Z","shell.execute_reply.started":"2024-03-16T04:51:50.845447Z","shell.execute_reply":"2024-03-16T04:51:50.882612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation set\ntest_texts, val_texts, test_labels, val_labels = train_test_split(\n\ttest_texts, test_labels, test_size=0.5, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.884613Z","iopub.execute_input":"2024-03-16T04:51:50.884943Z","iopub.status.idle":"2024-03-16T04:51:50.896779Z","shell.execute_reply.started":"2024-03-16T04:51:50.884916Z","shell.execute_reply":"2024-03-16T04:51:50.896065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Token and Encode Function\ndef tokenize_and_encode(tokenizer, comments, labels, max_length=128):\n\t# Initialize empty lists to store tokenized inputs and attention masks\n\tinput_ids = []\n\tattention_masks = []\n\n\t# Iterate through each comment in the 'comments' list\n\tfor comment in comments:\n\n\t\t# Tokenize and encode the comment using the BERT tokenizer\n\t\tencoded_dict = tokenizer.encode_plus(\n\t\t\tcomment,\n\n\t\t\t# Add special tokens like [CLS] and [SEP]\n\t\t\tadd_special_tokens=True,\n\n\t\t\t# Truncate or pad the comment to 'max_length'\n\t\t\tmax_length=max_length,\n\n\t\t\t# Pad the comment to 'max_length' with zeros if needed\n\t\t\tpad_to_max_length=True,\n\n\t\t\t# Return attention mask to mask padded tokens\n\t\t\treturn_attention_mask=True,\n\n\t\t\t# Return PyTorch tensors\n\t\t\treturn_tensors='pt'\n\t\t)\n\n\t\t# Append the tokenized input and attention mask to their respective lists\n\t\tinput_ids.append(encoded_dict['input_ids'])\n\t\tattention_masks.append(encoded_dict['attention_mask'])\n\n\t# Concatenate the tokenized inputs and attention masks into tensors\n\tinput_ids = torch.cat(input_ids, dim=0)\n\tattention_masks = torch.cat(attention_masks, dim=0)\n\n\t# Convert the labels to a PyTorch tensor with the data type float32\n\tlabels = torch.tensor(labels, dtype=torch.float32)\n\n\t# Return the tokenized inputs, attention masks, and labels as PyTorch tensors\n\treturn input_ids, attention_masks, labels\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.898188Z","iopub.execute_input":"2024-03-16T04:51:50.898502Z","iopub.status.idle":"2024-03-16T04:51:50.906243Z","shell.execute_reply.started":"2024-03-16T04:51:50.898476Z","shell.execute_reply":"2024-03-16T04:51:50.905279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Token Initialization\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n\t\t\t\t\t\t\t\t\t\tdo_lower_case=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:50.907415Z","iopub.execute_input":"2024-03-16T04:51:50.907672Z","iopub.status.idle":"2024-03-16T04:51:54.741376Z","shell.execute_reply.started":"2024-03-16T04:51:50.907650Z","shell.execute_reply":"2024-03-16T04:51:54.740604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Initialization\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n\t\t\t\t\t\t\t\t\t\t\t\t\tnum_labels=6)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:54.746005Z","iopub.execute_input":"2024-03-16T04:51:54.746303Z","iopub.status.idle":"2024-03-16T04:51:57.666932Z","shell.execute_reply.started":"2024-03-16T04:51:54.746277Z","shell.execute_reply":"2024-03-16T04:51:57.666137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = torch.device(\n\t'cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:57.668321Z","iopub.execute_input":"2024-03-16T04:51:57.668587Z","iopub.status.idle":"2024-03-16T04:51:58.002718Z","shell.execute_reply.started":"2024-03-16T04:51:57.668563Z","shell.execute_reply":"2024-03-16T04:51:58.001830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and Encode the comments and labels for the training set\ninput_ids, attention_masks, labels = tokenize_and_encode(\n\ttokenizer,\n\ttrain_texts,\n\ttrain_labels.values\n)\n\n# Tokenize and Encode the comments and labels for the test set\ntest_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n\ttokenizer,\n\ttest_texts,\n\ttest_labels.values\n)\n\n# Tokenize and Encode the comments and labels for the validation set\nval_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n\ttokenizer,\n\tval_texts,\n\tval_labels.values\n)\n\n\nprint('Training Comments :',train_texts.shape)\nprint('Input Ids\t\t :',input_ids.shape)\nprint('Attention Mask :',attention_masks.shape)\nprint('Labels\t\t :',labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:51:58.003996Z","iopub.execute_input":"2024-03-16T04:51:58.004410Z","iopub.status.idle":"2024-03-16T04:59:52.810466Z","shell.execute_reply.started":"2024-03-16T04:51:58.004373Z","shell.execute_reply":"2024-03-16T04:59:52.809465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 53\nprint('Training Comments -->>',train_texts.values[k])\nprint('\\nInput Ids -->>\\n',input_ids[k])\nprint('\\nDecoded Ids -->>\\n',tokenizer.decode(input_ids[k]))\nprint('\\nAttention Mask -->>\\n',attention_masks[k])\nprint('\\nLabels -->>',labels[k])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:59:52.811803Z","iopub.execute_input":"2024-03-16T04:59:52.812346Z","iopub.status.idle":"2024-03-16T04:59:52.867708Z","shell.execute_reply.started":"2024-03-16T04:59:52.812319Z","shell.execute_reply":"2024-03-16T04:59:52.866884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating DataLoader for the balanced dataset\nbatch_size = 32\ntrain_dataset = TensorDataset(input_ids, attention_masks, labels)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# testing set \ntest_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# validation set \nval_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:59:52.869035Z","iopub.execute_input":"2024-03-16T04:59:52.869687Z","iopub.status.idle":"2024-03-16T04:59:52.875825Z","shell.execute_reply.started":"2024-03-16T04:59:52.869659Z","shell.execute_reply":"2024-03-16T04:59:52.874984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Batch Size :',train_loader.batch_size)\nBatch =next(iter(train_loader))\nprint('Each Input ids shape :',Batch[0].shape)\nprint('Input ids :\\n',Batch[0][0])\nprint('Corresponding Decoded text:\\n',tokenizer.decode(Batch[0][0]))\nprint('Corresponding Attention Mask :\\n',Batch[1][0])\nprint('Corresponding Label:',Batch[2][0])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:59:52.877088Z","iopub.execute_input":"2024-03-16T04:59:52.877348Z","iopub.status.idle":"2024-03-16T04:59:52.911875Z","shell.execute_reply.started":"2024-03-16T04:59:52.877325Z","shell.execute_reply":"2024-03-16T04:59:52.911195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizer setup\noptimizer = AdamW(model.parameters(), lr=2e-5)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:59:52.912740Z","iopub.execute_input":"2024-03-16T04:59:52.913007Z","iopub.status.idle":"2024-03-16T04:59:52.920484Z","shell.execute_reply.started":"2024-03-16T04:59:52.912985Z","shell.execute_reply":"2024-03-16T04:59:52.919695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    # Get the name of the GPU\n    gpu_name = torch.cuda.get_device_name(0)\n    print(\"GPU:\", gpu_name)\nelse:\n    print(\"No GPU available, using CPU.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:59:52.921480Z","iopub.execute_input":"2024-03-16T04:59:52.921766Z","iopub.status.idle":"2024-03-16T04:59:52.928863Z","shell.execute_reply.started":"2024-03-16T04:59:52.921743Z","shell.execute_reply":"2024-03-16T04:59:52.928013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Train the Model\ndef train_model(model, train_loader, optimizer, device, num_epochs):\n\t# Loop through the specified number of epochs\n\tfor epoch in range(num_epochs):\n\t\t# Set the model to training mode\n\t\tmodel.train()\n\t\t# Initialize total loss for the current epoch\n\t\ttotal_loss = 0\n\n\t\t# Loop through the batches in the training data\n\t\tfor batch in train_loader:\n\t\t\tinput_ids, attention_mask, labels = [t.to(device) for t in batch]\n\n\t\t\toptimizer.zero_grad()\n\n\t\t\toutputs = model(\n\t\t\t\tinput_ids, attention_mask=attention_mask, labels=labels)\n\t\t\tloss = outputs.loss\n\t\t\ttotal_loss += loss.item()\n\n\t\t\tloss.backward()\n\t\t\toptimizer.step()\n\n\t\tmodel.eval() # Set the model to evaluation mode\n\t\tval_loss = 0\n\n\t\t# Disable gradient computation during validation\n\t\twith torch.no_grad():\n\t\t\tfor batch in val_loader:\n\t\t\t\tinput_ids, attention_mask, labels = [\n\t\t\t\t\tt.to(device) for t in batch]\n\n\t\t\t\toutputs = model(\n\t\t\t\t\tinput_ids, attention_mask=attention_mask, labels=labels)\n\t\t\t\tloss = outputs.loss\n\t\t\t\tval_loss += loss.item()\n\t\t# Print the average loss for the current epoch\n\t\tprint(\n\t\t\tf'Epoch {epoch+1}, Training Loss: {total_loss/len(train_loader)},Validation loss:{val_loss/len(val_loader)}')\n\n\n# Call the function to train the model\ntrain_model(model, train_loader, optimizer, device, num_epochs=3)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T04:59:52.929982Z","iopub.execute_input":"2024-03-16T04:59:52.930275Z","iopub.status.idle":"2024-03-16T07:09:51.040448Z","shell.execute_reply.started":"2024-03-16T04:59:52.930253Z","shell.execute_reply":"2024-03-16T07:09:51.039427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the Model\ndef evaluate_model(model, test_loader, device):\n\tmodel.eval() # Set the model to evaluation mode\n\n\ttrue_labels = []\n\tpredicted_probs = []\n\n\twith torch.no_grad():\n\t\tfor batch in test_loader:\n\t\t\tinput_ids, attention_mask, labels = [t.to(device) for t in batch]\n\n\t\t\t# Get model's predictions\n\t\t\toutputs = model(input_ids, attention_mask=attention_mask)\n\t\t\t# Use sigmoid for multilabel classification\n\t\t\tpredicted_probs_batch = torch.sigmoid(outputs.logits)\n\t\t\tpredicted_probs.append(predicted_probs_batch.cpu().numpy())\n\n\t\t\ttrue_labels_batch = labels.cpu().numpy()\n\t\t\ttrue_labels.append(true_labels_batch)\n\n\t# Combine predictions and labels for evaluation\n\ttrue_labels = np.concatenate(true_labels, axis=0)\n\tpredicted_probs = np.concatenate(predicted_probs, axis=0)\n\tpredicted_labels = (predicted_probs > 0.5).astype(\n\t\tint) # Apply threshold for binary classification\n\n\t# Calculate evaluation metrics\n\taccuracy = accuracy_score(true_labels, predicted_labels)\n\tprecision = precision_score(true_labels, predicted_labels, average='micro')\n\trecall = recall_score(true_labels, predicted_labels, average='micro')\n\n\t# Print the evaluation metrics\n\tprint(f'Accuracy: {accuracy:.4f}')\n\tprint(f'Precision: {precision:.4f}')\n\tprint(f'Recall: {recall:.4f}')\n\n\n# Call the function to evaluate the model on the test data\nevaluate_model(model, test_loader, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:09:51.041963Z","iopub.execute_input":"2024-03-16T07:09:51.042378Z","iopub.status.idle":"2024-03-16T07:12:14.369618Z","shell.execute_reply.started":"2024-03-16T07:09:51.042343Z","shell.execute_reply":"2024-03-16T07:12:14.368532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the tokenizer and model in the same directory\noutput_dir = \"Saved_model\"\n# Save model's state dictionary and configuration\nmodel.save_pretrained(output_dir)\n# Save tokenizer's configuration and vocabulary\ntokenizer.save_pretrained(output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:12:14.371404Z","iopub.execute_input":"2024-03-16T07:12:14.372143Z","iopub.status.idle":"2024-03-16T07:12:15.256100Z","shell.execute_reply.started":"2024-03-16T07:12:14.372104Z","shell.execute_reply":"2024-03-16T07:12:15.255189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the tokenizer and model from the saved directory\nmodel_name = \"Saved_model\"\nBert_Tokenizer = BertTokenizer.from_pretrained(model_name)\nBert_Model = BertForSequenceClassification.from_pretrained(\n\tmodel_name).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:12:15.257300Z","iopub.execute_input":"2024-03-16T07:12:15.257636Z","iopub.status.idle":"2024-03-16T07:12:15.672551Z","shell.execute_reply.started":"2024-03-16T07:12:15.257608Z","shell.execute_reply":"2024-03-16T07:12:15.671582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_user_input(input_text, model=Bert_Model, tokenizer=Bert_Tokenizer, device=device):\n\tuser_input = [input_text]\n\n\tuser_encodings = tokenizer(\n\t\tuser_input, truncation=True, padding=True, return_tensors=\"pt\")\n\n\tuser_dataset = TensorDataset(\n\t\tuser_encodings['input_ids'], user_encodings['attention_mask'])\n\n\tuser_loader = DataLoader(user_dataset, batch_size=1, shuffle=False)\n\n\tmodel.eval()\n\twith torch.no_grad():\n\t\tfor batch in user_loader:\n\t\t\tinput_ids, attention_mask = [t.to(device) for t in batch]\n\t\t\toutputs = model(input_ids, attention_mask=attention_mask)\n\t\t\tlogits = outputs.logits\n\t\t\tpredictions = torch.sigmoid(logits)\n\n\tpredicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)\n\tlabels_list = ['toxic', 'severe_toxic', 'obscene',\n\t\t\t\t'threat', 'insult', 'identity_hate']\n\tresult = dict(zip(labels_list, predicted_labels[0]))\n\treturn result\n\n\ntext = 'Are you insane!'\npredict_user_input(input_text=text)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:12:15.673780Z","iopub.execute_input":"2024-03-16T07:12:15.674119Z","iopub.status.idle":"2024-03-16T07:12:15.793028Z","shell.execute_reply.started":"2024-03-16T07:12:15.674092Z","shell.execute_reply":"2024-03-16T07:12:15.791982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_user_input(input_text='How are you?')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:12:15.794458Z","iopub.execute_input":"2024-03-16T07:12:15.794790Z","iopub.status.idle":"2024-03-16T07:12:15.816941Z","shell.execute_reply.started":"2024-03-16T07:12:15.794760Z","shell.execute_reply":"2024-03-16T07:12:15.816000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"Such an Idiot person\"\npredict_user_input(model=Bert_Model,\n\t\t\t\ttokenizer=Bert_Tokenizer,\n\t\t\t\tinput_text=text,\n\t\t\t\tdevice=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:12:15.817997Z","iopub.execute_input":"2024-03-16T07:12:15.818265Z","iopub.status.idle":"2024-03-16T07:12:15.839916Z","shell.execute_reply.started":"2024-03-16T07:12:15.818241Z","shell.execute_reply":"2024-03-16T07:12:15.839107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom zipfile import ZipFile\n\n# Define the folder you want to download\nfolder_name = \"Saved_model\"\n\n# Zip the folder\nzip_filename = folder_name + \".zip\"\nos.system(f\"zip -r {zip_filename} {folder_name}\")\n\n# Download the zipped folder\nfrom IPython.display import FileLink\nFileLink(zip_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:12:15.841023Z","iopub.execute_input":"2024-03-16T07:12:15.841339Z","iopub.status.idle":"2024-03-16T07:12:40.234497Z","shell.execute_reply.started":"2024-03-16T07:12:15.841313Z","shell.execute_reply":"2024-03-16T07:12:40.233583Z"},"trusted":true},"execution_count":null,"outputs":[]}]}